{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.18"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
      "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /tmp/pip-req-build-ragjvwwj\n",
      "  Running command git clone -q https://github.com/JustAnotherArchivist/snscrape.git /tmp/pip-req-build-ragjvwwj\n",
      "Requirement already satisfied (use --upgrade to upgrade): snscrape==0.3.5.dev104+g97c8cae from git+https://github.com/JustAnotherArchivist/snscrape.git in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from snscrape==0.3.5.dev104+g97c8cae) (4.9.3)\n",
      "Requirement already satisfied: lxml in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from snscrape==0.3.5.dev104+g97c8cae) (4.6.3)\n",
      "Requirement already satisfied: requests[socks] in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from snscrape==0.3.5.dev104+g97c8cae) (2.24.0)\n",
      "Requirement already satisfied: pytz in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from snscrape==0.3.5.dev104+g97c8cae) (2020.5)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from beautifulsoup4->snscrape==0.3.5.dev104+g97c8cae) (2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev104+g97c8cae) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev104+g97c8cae) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev104+g97c8cae) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev104+g97c8cae) (1.25.11)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /home/jan/git/hrw-deep-learning/pytorch/lib/python3.8/site-packages (from requests[socks]->snscrape==0.3.5.dev104+g97c8cae) (1.7.1)\n",
      "Building wheels for collected packages: snscrape\n",
      "  Building wheel for snscrape (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for snscrape: filename=snscrape-0.3.5.dev104+g97c8cae-py3-none-any.whl size=50541 sha256=8524e03c97016e3a7544b8d7ec4af9a44c57cd8a7bd0f7cd9b27e222525ef2e2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dsiujm4o/wheels/92/42/87/33fa9b18f7a75d02643a9ca3743339aec9be28c6796267c7d8\n",
      "Successfully built snscrape\n"
     ]
    }
   ],
   "source": [
    "#Install Development Version of SNScrape\n",
    "!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxTweets = 1000\n",
    "query_text = 'uniper'\n",
    "after = '2019-06-01'\n",
    "before = '2019-07-01'\n",
    "tweets = []\n",
    "user = None #add from:{username} in querystr!\n",
    "\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('{} since:{} until:{}'.format(query_text,after,before)).get_items()):\n",
    "    if i>maxTweets:\n",
    "        break\n",
    "    tweets.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.replyCount, tweet.likeCount, tweet.retweetCount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    Datetime             Tweet Id  \\\n",
       "0  2019-06-30 22:12:46+00:00  1145455159553794049   \n",
       "1  2019-06-30 21:01:04+00:00  1145437117608124416   \n",
       "2  2019-06-30 20:56:16+00:00  1145435907010584579   \n",
       "3  2019-06-30 20:49:16+00:00  1145434149068640256   \n",
       "4  2019-06-30 19:52:47+00:00  1145419931099586561   \n",
       "5  2019-06-30 15:54:40+00:00  1145360009137725441   \n",
       "6  2019-06-30 15:46:20+00:00  1145357910240825347   \n",
       "7  2019-06-30 15:11:08+00:00  1145349051233255425   \n",
       "8  2019-06-30 15:10:43+00:00  1145348947558449153   \n",
       "9  2019-06-30 12:24:08+00:00  1145307027088052224   \n",
       "10 2019-06-30 11:59:24+00:00  1145300800014573568   \n",
       "11 2019-06-30 04:31:15+00:00  1145188021538631680   \n",
       "12 2019-06-29 21:57:46+00:00  1145088999448621056   \n",
       "13 2019-06-29 16:32:03+00:00  1145007027451834369   \n",
       "14 2019-06-29 14:05:38+00:00  1144970179849404417   \n",
       "15 2019-06-29 11:52:18+00:00  1144936629376868352   \n",
       "16 2019-06-29 11:09:33+00:00  1144925868604764160   \n",
       "17 2019-06-29 07:10:40+00:00  1144865753621049344   \n",
       "18 2019-06-28 16:30:00+00:00  1144644126954049536   \n",
       "19 2019-06-28 13:36:53+00:00  1144600559661592577   \n",
       "\n",
       "                                                 Text       Username  \\\n",
       "0   @SvD @dagensnyheter @dagensindustri @sydsvensk...   JanEbenholtz   \n",
       "1   Uniper-Aktie: Kurs legt zu - https://t.co/dX3F...   frankkohanek   \n",
       "2   Uniper veut brûler les forêts françaises à Gar...    GREUBELINUX   \n",
       "3   @SvD @dagensnyheter @dagensindustri @sydsvensk...   JanEbenholtz   \n",
       "4   Topp seminarier idag var Uppsala Universitet t...    Simonliljas   \n",
       "5   ”Det finns en stor risk att vi fokuserar på ga...    StrandMalin   \n",
       "6   Bra diskussion hos Uniper om framtidens elsyst...   frankkronert   \n",
       "7   Nu börjar Almedalen! Inleder med @UniperSweden...       Ogglaton   \n",
       "8   @JohanSvenningss VD Uniper understryker att be...   UniperSweden   \n",
       "9   @SvD @dagensnyheter @dagensindustri @sydsvensk...   JanEbenholtz   \n",
       "10  @SvD @dagensnyheter @dagensindustri @sydsvensk...   JanEbenholtz   \n",
       "11  Uniper: Neutrale Bewegungen | InvestorSMS http...    InvestorSMS   \n",
       "12  @SvD @dagensnyheter @dagensindustri @sydsvensk...   JanEbenholtz   \n",
       "13  @DilanYesilgoz @lexhoogduin En de overheid moe...     larsroobol   \n",
       "14  @SvD @dagensnyheter @dagensindustri @sydsvensk...   JanEbenholtz   \n",
       "15  @Frits_E Goed te lezen dat de Rijksoverheid pr...      enroctoob   \n",
       "16  @Aubimed_ @gamingfoxDE @RWE_AG E.ON ist E.ON -...         EON_de   \n",
       "17  @gamingfoxDE @EON_de @RWE_AG Dikka juckt doch ...       Aubimed_   \n",
       "18  Bereit für einen Neuanfang in #SocialMedia, #S...  basicthinking   \n",
       "19  25-22 to @uniper_energy versus Scrambled Legs ...    MedwaySport   \n",
       "\n",
       "    Reply Count  Like Count  Retweet Count  \n",
       "0             0           0              0  \n",
       "1             0           0              0  \n",
       "2             0           0              0  \n",
       "3             0           0              0  \n",
       "4             0           0              0  \n",
       "5             0           8              3  \n",
       "6             0           7              1  \n",
       "7             0           2              0  \n",
       "8             1           1              0  \n",
       "9             0           0              0  \n",
       "10            0           0              0  \n",
       "11            0           0              0  \n",
       "12            0           0              0  \n",
       "13            1           4              0  \n",
       "14            0           0              0  \n",
       "15            0           9              5  \n",
       "16            0           0              0  \n",
       "17            2           0              0  \n",
       "18            0           3              1  \n",
       "19            0           3              0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Datetime</th>\n      <th>Tweet Id</th>\n      <th>Text</th>\n      <th>Username</th>\n      <th>Reply Count</th>\n      <th>Like Count</th>\n      <th>Retweet Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-06-30 22:12:46+00:00</td>\n      <td>1145455159553794049</td>\n      <td>@SvD @dagensnyheter @dagensindustri @sydsvensk...</td>\n      <td>JanEbenholtz</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-06-30 21:01:04+00:00</td>\n      <td>1145437117608124416</td>\n      <td>Uniper-Aktie: Kurs legt zu - https://t.co/dX3F...</td>\n      <td>frankkohanek</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-06-30 20:56:16+00:00</td>\n      <td>1145435907010584579</td>\n      <td>Uniper veut brûler les forêts françaises à Gar...</td>\n      <td>GREUBELINUX</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-06-30 20:49:16+00:00</td>\n      <td>1145434149068640256</td>\n      <td>@SvD @dagensnyheter @dagensindustri @sydsvensk...</td>\n      <td>JanEbenholtz</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-06-30 19:52:47+00:00</td>\n      <td>1145419931099586561</td>\n      <td>Topp seminarier idag var Uppsala Universitet t...</td>\n      <td>Simonliljas</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2019-06-30 15:54:40+00:00</td>\n      <td>1145360009137725441</td>\n      <td>”Det finns en stor risk att vi fokuserar på ga...</td>\n      <td>StrandMalin</td>\n      <td>0</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2019-06-30 15:46:20+00:00</td>\n      <td>1145357910240825347</td>\n      <td>Bra diskussion hos Uniper om framtidens elsyst...</td>\n      <td>frankkronert</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2019-06-30 15:11:08+00:00</td>\n      <td>1145349051233255425</td>\n      <td>Nu börjar Almedalen! Inleder med @UniperSweden...</td>\n      <td>Ogglaton</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2019-06-30 15:10:43+00:00</td>\n      <td>1145348947558449153</td>\n      <td>@JohanSvenningss VD Uniper understryker att be...</td>\n      <td>UniperSweden</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2019-06-30 12:24:08+00:00</td>\n      <td>1145307027088052224</td>\n      <td>@SvD @dagensnyheter @dagensindustri @sydsvensk...</td>\n      <td>JanEbenholtz</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2019-06-30 11:59:24+00:00</td>\n      <td>1145300800014573568</td>\n      <td>@SvD @dagensnyheter @dagensindustri @sydsvensk...</td>\n      <td>JanEbenholtz</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2019-06-30 04:31:15+00:00</td>\n      <td>1145188021538631680</td>\n      <td>Uniper: Neutrale Bewegungen | InvestorSMS http...</td>\n      <td>InvestorSMS</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2019-06-29 21:57:46+00:00</td>\n      <td>1145088999448621056</td>\n      <td>@SvD @dagensnyheter @dagensindustri @sydsvensk...</td>\n      <td>JanEbenholtz</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2019-06-29 16:32:03+00:00</td>\n      <td>1145007027451834369</td>\n      <td>@DilanYesilgoz @lexhoogduin En de overheid moe...</td>\n      <td>larsroobol</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2019-06-29 14:05:38+00:00</td>\n      <td>1144970179849404417</td>\n      <td>@SvD @dagensnyheter @dagensindustri @sydsvensk...</td>\n      <td>JanEbenholtz</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2019-06-29 11:52:18+00:00</td>\n      <td>1144936629376868352</td>\n      <td>@Frits_E Goed te lezen dat de Rijksoverheid pr...</td>\n      <td>enroctoob</td>\n      <td>0</td>\n      <td>9</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2019-06-29 11:09:33+00:00</td>\n      <td>1144925868604764160</td>\n      <td>@Aubimed_ @gamingfoxDE @RWE_AG E.ON ist E.ON -...</td>\n      <td>EON_de</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2019-06-29 07:10:40+00:00</td>\n      <td>1144865753621049344</td>\n      <td>@gamingfoxDE @EON_de @RWE_AG Dikka juckt doch ...</td>\n      <td>Aubimed_</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2019-06-28 16:30:00+00:00</td>\n      <td>1144644126954049536</td>\n      <td>Bereit für einen Neuanfang in #SocialMedia, #S...</td>\n      <td>basicthinking</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2019-06-28 13:36:53+00:00</td>\n      <td>1144600559661592577</td>\n      <td>25-22 to @uniper_energy versus Scrambled Legs ...</td>\n      <td>MedwaySport</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "tweets_df = pd.DataFrame(tweets, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'Reply Count', 'Like Count', 'Retweet Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "first Tweet: 2019-06-01 00:44:17+00:00\nlast Tweet: 2019-06-30 22:12:46+00:00\n"
     ]
    }
   ],
   "source": [
    "print('first Tweet: {}'.format(tweets_df['Datetime'].min()))\n",
    "print('last Tweet: {}'.format(tweets_df['Datetime'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Datetime\n",
       "2019-06-01 00:00:00+00:00     7\n",
       "2019-06-02 00:00:00+00:00     5\n",
       "2019-06-03 00:00:00+00:00    30\n",
       "2019-06-04 00:00:00+00:00    12\n",
       "2019-06-05 00:00:00+00:00    46\n",
       "2019-06-06 00:00:00+00:00    31\n",
       "2019-06-07 00:00:00+00:00    21\n",
       "2019-06-08 00:00:00+00:00     5\n",
       "2019-06-09 00:00:00+00:00    11\n",
       "2019-06-10 00:00:00+00:00    10\n",
       "2019-06-11 00:00:00+00:00    31\n",
       "2019-06-12 00:00:00+00:00    35\n",
       "2019-06-13 00:00:00+00:00    41\n",
       "2019-06-14 00:00:00+00:00    36\n",
       "2019-06-15 00:00:00+00:00    15\n",
       "2019-06-16 00:00:00+00:00     6\n",
       "2019-06-17 00:00:00+00:00    14\n",
       "2019-06-18 00:00:00+00:00    17\n",
       "2019-06-19 00:00:00+00:00    19\n",
       "2019-06-20 00:00:00+00:00    12\n",
       "2019-06-21 00:00:00+00:00    11\n",
       "2019-06-22 00:00:00+00:00     4\n",
       "2019-06-23 00:00:00+00:00     9\n",
       "2019-06-24 00:00:00+00:00    27\n",
       "2019-06-25 00:00:00+00:00     9\n",
       "2019-06-26 00:00:00+00:00    19\n",
       "2019-06-27 00:00:00+00:00    25\n",
       "2019-06-28 00:00:00+00:00    11\n",
       "2019-06-29 00:00:00+00:00     6\n",
       "2019-06-30 00:00:00+00:00    12\n",
       "Freq: D, Name: Tweet Id, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "tweets_df.groupby(pd.Grouper(key='Datetime',freq='D')).count()['Tweet Id']"
   ]
  }
 ]
}